{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba3accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1148c2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dl-energy-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %% load packages\n",
    "import locale\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import requests\n",
    "import torch\n",
    "import random\n",
    "from sqlalchemy import create_engine,inspect\n",
    "from pathlib import Path\n",
    "import urllib.parse\n",
    "import pyarrow\n",
    "from calendar import day_abbr\n",
    "import calendar\n",
    "from typing import Tuple, Union, Dict, List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pygam import LinearGAM, s\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d49975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from srs.utils.tutor_utils import prepare_dataset_tensor, forecasting_study,\\\n",
    "  plot_daily_profile,plot_hour_comparison, build_multiwindow_experts, tune_ewa_eta, \\\n",
    "  ewa_aggregate_forecasts, compute_error_table, tune_expert_window, \\\n",
    "  run_expert_window_test, build_regression_matrix, SimpleMLP, train_mlp, \\\n",
    "  prepare_train_test_tensors, build_mlp_rolling_forecasts, tune_mlp_hyperparameters, \\\n",
    "  DST_trafo\n",
    "  \n",
    "from srs.utils.our_utils import run_forecast_step\n",
    "from srs.collect_data.setup import setup_seed, get_device\n",
    "from srs.collect_data.entsoe_data import create_entsoe_engine, get_tables, get_spec, \\\n",
    "  get_market_divisions,get_map_codes,get_map_codes_starting_with, get_resolution_codes, \\\n",
    "    prepare_generation, prepare_load,prepare_price, prepare_unavailability, \\\n",
    "    prepare_filling_rate_hydro, prepare_physical_flow, prepare_installed_capacity\n",
    "from srs.collect_data.datastream_data import create_datastream_engine, get_tables, \\\n",
    "  prepare_datastream\n",
    "from srs.collect_data.dwd_mosmix_data import fetch_region_weather, prepare_weather\n",
    "from srs.collect_data.merge_data import merge_datasets, build_training_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd91127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Transform merged dataset using DST_trafo and prepare training data.\n",
    "\n",
    "repo_root = Path.cwd().parents[1]\n",
    "data_no1 = pd.read_csv(repo_root / \"data\" /'data_no1.csv')\n",
    "data_t_no1, train_t_no1, train_dates, price_t_no1 = prepare_dataset_tensor(\n",
    "    repo_root / \"data\" / \"data_no1.csv\",\n",
    "    tz=\"CET\",\n",
    "    seed=42,\n",
    "    test_days=2*365,         \n",
    "    dtype=torch.float64, \n",
    ")\n",
    "\n",
    "data_array = data_t_no1         \n",
    "price_S    = price_t_no1        \n",
    "dates_S    = train_dates    \n",
    "\n",
    "D          = 730            \n",
    "N          = 2 * 365\n",
    "S          = 24\n",
    "WD         = [1, 6, 7]\n",
    "PRICE_S_LAGS = [1, 2, 7]\n",
    "da_lag = [0]\n",
    "\n",
    "#validation period length\n",
    "length_eval = 2 * 365\n",
    "\n",
    "# The first obdervation in the evaluation period\n",
    "begin_eval = data_array.shape[0] - length_eval\n",
    "dat_eval = data_array[:-N,:,:]\n",
    "days_eval = pd.to_datetime(dates_S)[:-N]\n",
    "N_s = length_eval\n",
    "\n",
    "model_names = [\n",
    "    \"true\",\n",
    "    \"expert_ext\",\n",
    "    \"linar_gam\",\n",
    "    \"light_gbm\"\n",
    "]\n",
    "n_models = len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D tensor to hold forecasts:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "forecasts = torch.full((N_s, S, n_models), float('nan'), dtype=torch.float64, device=device)\n",
    "\n",
    "init_time = datetime.now()\n",
    "# 2. Create thread pool\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            run_forecast_step,\n",
    "            n,\n",
    "            price_S,\n",
    "            data_array,\n",
    "            begin_eval,\n",
    "            D,\n",
    "            dates_S,\n",
    "            WD,\n",
    "            PRICE_S_LAGS,\n",
    "            da_lag,\n",
    "            data_no1.columns[1:],  # reg_names\n",
    "            data_no1.columns[1:]   # data_columns\n",
    "        )\n",
    "        for n in range(N_s)\n",
    "    ]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            n, gam = future.result()\n",
    "            #forecasts[n, :, 1] = torch.tensor(gam, dtype=forecasts.dtype, device=forecasts.device)\n",
    "            forecasts[n, :, 1] = gam.detach().clone().to(forecasts.dtype).to(forecasts.device)\n",
    "            #forecasts[n, :, insert_order] = true_price\n",
    "            #forecasts[n, :, insert_order] = torch.tensor(expert, dtype=forecasts.dtype, device=forecasts.device)\n",
    "            #forecasts[n, :, insert_order] = torch.tensor(lg_gbm, dtype=forecasts.dtype, device=forecasts.device)\n",
    "        except Exception as e:\n",
    "            print(f\"Thread crashed: {e}\")\n",
    "\n",
    "# End timing\n",
    "end_time = datetime.now()\n",
    "duration_minutes = (end_time - init_time).total_seconds() / 60\n",
    "print(f\"\\nParallel training duration (threaded): {duration_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5221d4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2193, 24, 10])\n",
      "torch.Size([2193, 24])\n",
      "(2193,)\n"
     ]
    }
   ],
   "source": [
    "print(data_array.shape )\n",
    "print(price_S.shape )\n",
    "print(dates_S.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6045102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2193, 24, 10])\n",
      "torch.Size([2193, 24])\n",
      "(2193,)\n",
      "torch.Size([2193, 24, 10])\n"
     ]
    }
   ],
   "source": [
    "print(data_t_no1.shape)\n",
    "print(price_t_no1.shape)\n",
    "print(train_dates.shape)\n",
    "print(train_t_no1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc172c98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# -------------------------------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# estimate results using train and validation datasets\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# estimate rmse for all models, validation dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m true_price = price_S[begin_eval + n]\n\u001b[32m      5\u001b[39m forecasts[:, :, \u001b[32m0\u001b[39m] = true_price\n\u001b[32m      6\u001b[39m true_values = forecasts[:, :, \u001b[32m0\u001b[39m] \n",
      "\u001b[31mNameError\u001b[39m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------------------------------------------------\n",
    "# estimate results using train and validation datasets\n",
    "# estimate rmse for all models, validation dataset\n",
    "true_values = forecasts[:, :, 0] \n",
    "\n",
    "# Add a new axis to true_values to allow broadcasting\n",
    "true_expanded = true_values.unsqueeze(-1) \n",
    "\n",
    "# Repeat along last dim\n",
    "FFT = true_expanded.repeat(1, 1, forecasts.shape[2]) \n",
    "squared_errors = (FFT - forecasts) ** 2  \n",
    "\n",
    "\n",
    "# Average squared error over all days and hours (dim=0 and dim=1)\n",
    "mse_per_model = squared_errors.mean(dim=(0, 1))\n",
    "\n",
    "# Take square root to get RMSE per model\n",
    "rmse_per_model = torch.sqrt(mse_per_model) \n",
    "print(rmse_per_model)\n",
    "\n",
    "# %%#####################################################################\n",
    "#######################Comparison Plots##################################\n",
    "#######################################################################\n",
    "\n",
    "# chart for a specific hour and days\n",
    "#select the hour, chart for a specific hour\n",
    "hour = 14\n",
    "# Select the actual and forecasted prices for the specific hour\n",
    "true_values = forecasts[:, hour, 0].cpu().numpy()\n",
    "forecast_values = forecasts[:, hour, 1].cpu().numpy()\n",
    "\n",
    "#Specify the dates of the test data\n",
    "dates_x = days_eval[-N:]\n",
    "# Line plot comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(dates_x, true_values, label=\"True\")\n",
    "plt.plot(dates_x, forecast_values, label=\"Forecast (Expert)\", alpha=0.7, linewidth=2)\n",
    "plt.title(f\"Forecast vs True Values at hour {hour} Across Test Data\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#%%\n",
    "# chart for the last days\n",
    "# Select last days, chart for one day \n",
    "obs =  -15\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(forecasts[obs:, :, 0].flatten().cpu().numpy(), label=\"True\", linewidth=2)\n",
    "plt.plot(forecasts[obs:, :, 1].flatten().cpu().numpy(), label=\"Expert Forecast\", linestyle=\"--\")\n",
    "plt.plot(forecasts[obs:, :, 2].flatten().cpu().numpy(), label=\"GAM\", linestyle=\":\")\n",
    "plt.plot(forecasts[obs:, :, 3].flatten().cpu().numpy(), label=\"light gbm\", linestyle=\"--\")\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# chart for validation data\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(forecasts[:, :, 0].flatten().cpu().numpy(), label=\"True\", linewidth=2)\n",
    "plt.plot(forecasts[:, :, 1].flatten().cpu().numpy(), label=\"Expert Forecast\", linestyle=\"--\")\n",
    "plt.plot(forecasts[:, :, 2].flatten().cpu().numpy(), label=\"GAM\", linestyle=\":\")\n",
    "plt.plot(forecasts[:, :, 3].flatten().cpu().numpy(), label=\"light gbm\", linestyle=\"--\")\n",
    "plt.xlabel(\"Hours\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#%%#######################################################\n",
    "############## Test Data ###############\n",
    "###########################################################\n",
    "\n",
    "# Use all data including the test data\n",
    "days_test = pd.to_datetime(dates_S)\n",
    "dat_test = data_array\n",
    "\n",
    "#%%#######################################################\n",
    "##############Define test data###############\n",
    "##########################################################\n",
    "\n",
    "#  Define the test period length\n",
    "length_test = (2 * 365 )\n",
    "\n",
    "# The first obdervation in the evaluation period\n",
    "begin_test = days_test.shape[0] - length_test\n",
    "\n",
    "N_s = length_test\n",
    "\n",
    "# Initialize a 3D tensor to hold forecasts:\n",
    "forecasts_test = torch.full((N_s, S, n_models), float('nan'), dtype=torch.float64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4770eb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-energy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
